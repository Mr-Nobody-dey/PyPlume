{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# access thredds\n",
    "\n",
    "Download sliced netcdf data from Thredds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "from pyplume.constants import FIELD_NETCDF_DIR\n",
    "from pyplume.dataloaders import slice_dataset, dataset_to_fieldset\n",
    "from pyplume import utils\n",
    "from pyplume.thredds_data import retrieve_dataset, retrieve_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_span(delta):\n",
    "    # GMT, data recorded hourly\n",
    "    time_now = np.datetime64(\"now\", \"h\")\n",
    "    return (time_now - delta, time_now)\n",
    "\n",
    "def get_regs_year(year, name, lat_rng, lon_rng):\n",
    "    regions = []\n",
    "    months = np.arange(str(year), str(year + 1), dtype=\"datetime64[M]\")\n",
    "    for m in months:\n",
    "        days = np.arange(m, m + np.timedelta64(1, \"M\"), dtype=\"datetime64[D]\")\n",
    "        timerng = (np.datetime64(days[0], \"h\"), days[-1] + np.timedelta64(23, \"h\"))\n",
    "        for code in (\"USWC_1KM_HOURLY\", \"USWC_2KM_HOURLY\", \"USWC_6KM_HOURLY\"):\n",
    "            regions.append({\n",
    "                \"name\": f\"{name}_{m}\",\n",
    "                \"code\": code,\n",
    "                \"time_range\": timerng,\n",
    "                \"lat_range\": lat_rng,\n",
    "                \"lon_range\": lon_rng,\n",
    "                \"include_range_endpoints\": False if code == \"USWC_1KM_HOURLY\" else True\n",
    "            })\n",
    "    return regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### format of region_data stuff\n",
    "\n",
    "(name, resolution, time range, lat range, lon range, expand range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### about tj_sample\n",
    "\n",
    "the purpose of tj_sample is a quick and dirty way to sample the thredds data from a bunch of different times to find out the positions of where data exists. data in close time ranges could all have the same holes in data, and we would never know if data was supposed to be there in the first place.\n",
    "\n",
    "so tj_sample is generated for the sole purpose of creating a mask showing where data shouldn't exist.\n",
    "\n",
    "## data masks\n",
    "\n",
    "where is there data? every timestep of HFR data is not always complete, so we need to know what nan points were supposed to have data and which ones were never meant to have data.\n",
    "\n",
    "A good way to find this out is to take several slices of data over a long period of time and check the coverage of each timestamp. This is the easiest way to kind of see the true coverage of HFR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuple reference\n",
    "# (name, region code, time range, lat range, lon range, include domain endpoints)\n",
    "region_data = [\n",
    "    # {\n",
    "    #     \"name\": \"tj_sample\",\n",
    "    #     \"datasrc\": \"THREDDS_HFRNET_UCSD\",\n",
    "    #     \"code\": \"USWC_1KM_HOURLY\",\n",
    "    #     \"time_range\": (\"2019-01-01T00\", \"2021-01-01T00\", 300),\n",
    "    #     \"lat_range\": (32.11093, 32.73124),\n",
    "    #     \"lon_range\": (-117.565, -116.9924),\n",
    "    #     \"include_range_endpoints\": False\n",
    "    # },\n",
    "    # {\n",
    "    #     \"name\": \"hunington_latest\",\n",
    "    #     \"datasrc\": \"THREDDS_HFRNET_UCSD\",\n",
    "    #     \"code\": \"USWC_6KM_HOURLY\",\n",
    "    #     \"time_range\": (\"2021-10-01T00\", \"2021-10-10T00\"),\n",
    "    #     \"lat_range\": (32, 34.2),\n",
    "    #     \"lon_range\": (-119, -117.4),\n",
    "    #     \"include_range_endpoints\": True\n",
    "    # },\n",
    "    # {\n",
    "    #     \"name\": \"tj_plume_1km_2020-03\",\n",
    "    #     \"datasrc\": \"THREDDS_HFRNET_UCSD\",\n",
    "    #     \"code\": \"USWC_1KM_HOURLY\",\n",
    "    #     \"time_range\": (\"2020-03-09T01:00\", \"2020-03-14T01:00\"),\n",
    "    #     \"lat_range\": (32.11093, 32.73124),\n",
    "    #     \"lon_range\": (-117.565, -116.9924),\n",
    "    #     \"include_range_endpoints\": True,\n",
    "    #     \"generate_mask\": True\n",
    "    # },\n",
    "    # {\n",
    "    #   \"name\": \"hycom_mwbproj\",\n",
    "    #   \"datasrc\": \"THREDDS_HYCOM\",\n",
    "    #   \"code\": \"FMRC_HYCOM\",\n",
    "    #   \"time_range\": (np.datetime64(\"now\") - np.timedelta64(1, \"D\"), np.datetime64(\"now\") + np.timedelta64(7, \"D\")),\n",
    "    #   \"lat_range\": (22, 45),\n",
    "    #   \"lon_range\": (273, 295),\n",
    "    #   \"include_range_endpoints\": False\n",
    "    # },\n",
    "    # {\n",
    "    #   \"name\": \"tj_plume_1km_2022-09\",\n",
    "    #   \"datasrc\": \"THREDDS_HFRNET_UCSD\",\n",
    "    #   \"code\": \"USWC_1KM_HOURLY\",\n",
    "    #   \"time_range\": (\"2022-09-01T00:00\", \"2022-09-30T23:00\"),\n",
    "    #   \"lat_range\": (32.11093, 32.73124),\n",
    "    #   \"lon_range\": (-117.565, -116.9924),\n",
    "    #   \"include_range_endpoints\": True,\n",
    "    #   \"generate_mask\": True\n",
    "    # },\n",
    "    {\n",
    "      \"name\": \"hycom_hurrhenri\",\n",
    "      \"datasrc\": \"THREDDS_HYCOM\",\n",
    "      \"code\": \"GLOBAL_HINDCAST\",\n",
    "      \"time_range\": (\"2021-08-21T12:00\", \"2021-08-23T18:00\"),\n",
    "      \"lat_range\": (38.162201, 41.520008),\n",
    "      \"lon_range\": (284.290368, 290.276249),\n",
    "      \"include_range_endpoints\": True,\n",
    "      \"generate_mask\": False\n",
    "    }\n",
    "    # stuff below here hasn't been updated with the new format\n",
    "#     (\"tj_plume\", \"USWC_1KM_HOURLY\", (\"2020-08-01T01\", \"2020-08-14T13\"), (32.11093, 32.73124), (-117.565, -116.9924), False),\n",
    "#     (\"tj_plume\", \"USWC_2KM_HOURLY\", (\"2020-08-01T01\", \"2020-08-14T13\"), (32.11093, 32.73124), (-117.565, -116.9924), True),\n",
    "#     (\"tj_plume\", \"USWC_6KM_HOURLY\", (\"2020-08-01T01\", \"2020-08-14T13\"), (32.11093, 32.73124), (-117.565, -116.9924), True),\n",
    "#     (\"tijuana_river\", \"USWC_1KM_HOURLY\", (\"2020-06-16T21\", \"2020-06-23T21\"), (32.528, 32.71), (-117.29, -117.11), False),\n",
    "#     (\"tijuana_river\", \"USWC_2KM_HOURLY\", (\"2020-06-16T21\", \"2020-06-23T21\"), (32.524, 32.75), (-117.32, -117.09), False),\n",
    "#     (\"tijuana_river\", \"USWC_6KM_HOURLY\", (\"2020-06-16T21\", \"2020-06-23T21\"), (32.35, 32.80), (-117.33, -116.9), False),\n",
    "#     (\"tijuana_river_small\", \"USWC_1KM_HOURLY\", (\"2020-06-16T21\", \"2020-06-23T21\"), (32.528, 32.6), (-117.19, -117.11), False)\n",
    "#     (\"tijuana_river_now\", \"USWC_1KM_HOURLY\", get_latest_span(np.timedelta64(300, \"D\")), (32.528, 32.71), (-117.29, -117.11), False),\n",
    "#     (\"tijuana_river_now\", \"USWC_2KM_HOURLY\", get_latest_span(np.timedelta64(300, \"D\")), (32.524, 32.75), (-117.32, -117.09), False),\n",
    "#     (\"tijuana_river_now\", \"USWC_6KM_HOURLY\", (\"2019-09-28T21:00\", \"2020-07-24T20\"), (32.35, 32.80), (-117.33, -116.9), False),\n",
    "#     (\"missing_buoy\", \"USWC_6KM_HOURLY\", (\"2021-01-29T05\", \"2021-02-02T16\"), (33.15, 33.778072), (-118.697986, -117.6), False)\n",
    "]\n",
    "\n",
    "\n",
    "# for rd in get_regs_year(2020, \"tj_plume\", (32.11093, 32.73124), (-117.565, -116.9924)):\n",
    "#     region_data.append(rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_dir = utils.get_dir(FIELD_NETCDF_DIR)\n",
    "regions = []\n",
    "for rd in region_data:\n",
    "    print(rd)\n",
    "    with retrieve_dataloader(\n",
    "        rd[\"datasrc\"], rd[\"code\"], time_range=rd[\"time_range\"], lat_range=rd[\"lat_range\"],\n",
    "        lon_range=rd[\"lon_range\"], inclusive=rd[\"include_range_endpoints\"]\n",
    "    ) as dl:\n",
    "        dl.save(save_dir / f\"{rd['name']}.nc\")\n",
    "        if rd.get(\"generate_mask\", False):\n",
    "            dl.save_mask(save_dir / f\"{rd['name']}_mask.npy\", num_samples=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('py3-parcels')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "0eba6c4b74a2f8ee4f11000f0a8df2ef42b87fd4ae75b12d527f1b8c08aad6c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
