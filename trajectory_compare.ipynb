{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trajectory_compare\n",
    "\n",
    "compare multiple particle trajectory files and .mat outputs with the same spawn points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import utils\n",
    "from parcels_utils import arrays_to_particlefilenc\n",
    "from plot_utils import plot_trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_part_hash(ds, i):\n",
    "    lat = ds[\"lat\"].values[i, 0]\n",
    "    lon = ds[\"lon\"].values[i, 0]\n",
    "    return hash((lat, lon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first file in list is used as a reference for every particle's starting point\n",
    "particle_file_paths = [\n",
    "    \"particle_plume_track.nc\",\n",
    "    \"particle_plume_track_totsdlj.nc\",\n",
    "#     \"plume_pts_20200810_0030.nc\",\n",
    "]\n",
    "\n",
    "particle_files = []\n",
    "for path in particle_file_paths:\n",
    "    with xr.open_dataset(utils.PARTICLE_NETCDF_DIR / path) as pf:\n",
    "        particle_files.append(pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_file = particle_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_ids = np.empty(ref_file.dims[\"traj\"])\n",
    "for i in range(ref_file.dims[\"traj\"]):\n",
    "    particle_ids[i] = get_part_hash(ref_file, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iterates through the points in the reference netcdf and treats them as spawn points\n",
    "\n",
    "then it checks all the other netcdf files for points with the same spawn, and then graphs them to compare\n",
    "\n",
    "saves a separate netcdf file for each spawn and each different particle file given\n",
    "\n",
    "plots of the comparisons are saved under `snapshots/plume_compare/hash_of_position.png` where hash_of_position is just (lat, lon) tuple hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = 2000\n",
    "end = 2050\n",
    "\n",
    "plot_path = utils.create_path(utils.PICUTRE_DIR / \"plume_compare\")\n",
    "for p in plot_path.glob(\"*.png\"):\n",
    "    p.unlink()\n",
    "    \n",
    "for p_id in particle_ids[start:end]:\n",
    "    nc_files = []\n",
    "    num_format = format(p_id, \".0f\")\n",
    "    for pf_i in range(len(particle_files)):\n",
    "        pf = particle_files[pf_i]\n",
    "        for i in range(pf.dims[\"traj\"]):\n",
    "            if p_id != get_part_hash(pf, i):\n",
    "                continue\n",
    "            save_path = utils.create_path(plot_path / f\"{num_format}\")\n",
    "            time = pf[\"time\"].values[np.newaxis, i]\n",
    "            lat = pf[\"lat\"].values[np.newaxis, i]\n",
    "            lon = pf[\"lon\"].values[np.newaxis, i]\n",
    "            # recreate particle netcdf to drop data we don't need\n",
    "            ds = arrays_to_particlefilenc(time, lat, lon)\n",
    "            name = particle_file_paths[pf_i].split(\"/\")[-1].split(\".\")[0]\n",
    "            ds.to_netcdf(f\"{save_path / Path(name)}.nc\")\n",
    "            nc_files.append(f\"{save_path / Path(name)}.nc\")\n",
    "            break\n",
    "    plot_trajectories(nc_files, legend=True, savefile=plot_path / f\"{num_format}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_parcels",
   "language": "python",
   "name": "py3_parcels"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
