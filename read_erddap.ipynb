{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from erddapy import ERDDAP\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "import io\n",
    "from pathlib import Path\n",
    "from tempfile import NamedTemporaryFile\n",
    "from typing import Dict, Optional, Generator\n",
    "from typing.io import BinaryIO\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "import requests\n",
    "import xarray as xr\n",
    "\n",
    "# remove shit related to auth because idk what that does\n",
    "\n",
    "def _urlopen(url: str, **kwargs: Dict) -> BinaryIO:\n",
    "    response = requests.get(url, allow_redirects=True, **kwargs)\n",
    "    try:\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        raise requests.exceptions.HTTPError(f\"{response.content.decode()}\") from err\n",
    "    return io.BytesIO(response.content)\n",
    "\n",
    "def urlopen(url: str, **kwargs: Dict) -> BinaryIO:\n",
    "    \"\"\"Thin wrapper around requests get content.\n",
    "    See requests.get docs for the `params` and `kwargs` options.\n",
    "    \"\"\"\n",
    "    # Ignoring type checks here b/c mypy does not support decorated functions.\n",
    "    data = _urlopen(url=url, **kwargs)  # type: ignore\n",
    "    data.seek(0)\n",
    "    return data\n",
    "\n",
    "def _tempnc(data: BinaryIO) -> Generator[str, None, None]:\n",
    "    \"\"\"Creates a temporary netcdf file.\"\"\"\n",
    "    tmp = None\n",
    "    try:\n",
    "        tmp = NamedTemporaryFile(suffix=\".nc\", prefix=\"erddapy_\")\n",
    "        tmp.write(data.read())\n",
    "        tmp.flush()\n",
    "        yield tmp.name\n",
    "    finally:\n",
    "        if tmp is not None:\n",
    "            tmp.close()\n",
    "\n",
    "def _nc_dataset(url, auth, **requests_kwargs: Dict):\n",
    "    \"\"\"Returns a netCDF4-python Dataset from memory and fallbacks to disk if that fails.\"\"\"\n",
    "\n",
    "    data = urlopen(url=url)\n",
    "    try:\n",
    "        return Dataset(Path(urlparse(url).path).name, memory=data.read())\n",
    "    except OSError:\n",
    "        # if libnetcdf is not compiled with in-memory support fallback to a local tmp file\n",
    "        with _tempnc(data) as _nc:\n",
    "            return Dataset(_nc)\n",
    "\n",
    "def _quote_string_constraints(kwargs: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    For constraints of String variables,\n",
    "    the right-hand-side value must be surrounded by double quotes.\n",
    "    \"\"\"\n",
    "    return {k: f'\"{v}\"' if isinstance(v, str) else v for k, v in kwargs.items()}\n",
    "\n",
    "def _format_constraints_url(kwargs: Dict) -> str:\n",
    "    \"\"\"\n",
    "    Join the constraint variables with separator '&' to add to the download link.\n",
    "    \"\"\"\n",
    "    return \"\".join([f\"&{k}{v}\" for k, v in kwargs.items()])\n",
    "\n",
    "def _distinct(url: str, **kwargs: Dict) -> str:\n",
    "    \"\"\"\n",
    "    Sort all of the rows in the results table\n",
    "    (starting with the first requested variable,\n",
    "    then using the second requested variable if the first variable has a tie, ...),\n",
    "    then remove all non-unique rows of data.\n",
    "    For example, a query for the variables [\"stationType\", \"stationID\"] with `distinct=True`\n",
    "    will return a sorted list of \"stationIDs\" associated with each \"stationType\".\n",
    "    See https://coastwatch.pfeg.noaa.gov/erddap/tabledap/documentation.html#distinct\n",
    "    \"\"\"\n",
    "    distinct = kwargs.pop(\"distinct\", False)\n",
    "    if distinct is True:\n",
    "        return f\"{url}&distinct()\"\n",
    "    return url\n",
    "\n",
    "def get_download_url_griddap(\n",
    "    server,\n",
    "    dataset_id,\n",
    "    variables=None,\n",
    "    constraints=None,\n",
    "    relative_constraints=None,\n",
    "    **kwargs\n",
    ") -> str:\n",
    "    \"\"\"The download URL for the `server` endpoint.\n",
    "    Args:\n",
    "        server: server url\n",
    "        dataset_id: a dataset unique id.\n",
    "        variables (list/tuple): a list of the variables to download.\n",
    "        constraints (dict): download constraints, default None (opendap-like url)\n",
    "        example: constraints = {'latitude<=': 41.0,\n",
    "                                'latitude>=': 38.0,\n",
    "                                'longitude<=': -69.0,\n",
    "                                'longitude>=': -72.0,\n",
    "                                'time<=': '2017-02-10T00:00:00+00:00',\n",
    "                                'time>=': '2016-07-10T00:00:00+00:00',}\n",
    "        relative_constraints (dict): advanced download constraints , default None\n",
    "        example: relative_constraints = {'time>': 'now-7days',\n",
    "                                     'latitude<':'min(longitude)+180'\n",
    "                                     'depth>':'max(depth)-23'\n",
    "                                        }\n",
    "    Returns:\n",
    "        url (str): the download URL for the `response` chosen.\n",
    "    \"\"\"\n",
    "    if not dataset_id:\n",
    "        raise ValueError(f\"Please specify a valid `dataset_id`, got {dataset_id}\")\n",
    "\n",
    "    url = f\"{server}/griddap/{dataset_id}.nc?\"\n",
    "\n",
    "    if variables:\n",
    "        url += \",\".join(variables)\n",
    "\n",
    "    if constraints:\n",
    "        _constraints = copy.copy(constraints)\n",
    "        for k, v in _constraints.items():\n",
    "            if k.startswith(\"time\"):\n",
    "                _constraints.update({k: parse_dates(v)})\n",
    "        _constraints = _quote_string_constraints(_constraints)\n",
    "        _constraints_url = _format_constraints_url(_constraints)\n",
    "\n",
    "        url += f\"{_constraints_url}\"\n",
    "\n",
    "    if relative_constraints:\n",
    "        _relative_constraints_url = _format_constraints_url(relative_constraints)\n",
    "        url += f\"{_relative_constraints_url}\"\n",
    "\n",
    "    url = _distinct(url, **kwargs)\n",
    "    return url\n",
    "\n",
    "def to_xr_nc4(\n",
    "    server,\n",
    "    dataset_id,\n",
    "    variables=None,\n",
    "    constraints=None,\n",
    "    relative_constraints=None,\n",
    "    **kwargs\n",
    ") -> xr.backends.NetCDF4DataStore:\n",
    "    \"\"\"Load the data request into a xarray.backends.NetCDF4DataStore.\"\"\"\n",
    "    url = get_download_url_griddap(\n",
    "        server, dataset_id, variables, constraints, relative_constraints, **kwargs\n",
    "    )\n",
    "    nc = _nc_dataset(url)\n",
    "    return xr.backends.NetCDF4DataStore(nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erddap = ERDDAP(\n",
    "    server=\"https://erddap.sccoos.org/erddap\",\n",
    "    protocol=\"griddap\",\n",
    "    response=\"nc\",\n",
    ")\n",
    "erddap.dataset_id = \"roms_ncst\"\n",
    "erddap.variables = [\n",
    "    \"latitude\",\n",
    "    \"time\",\n",
    "]\n",
    "erddap.constraints = {\n",
    "    \"time>=\": \"2016-09-03T00:00:00Z\",\n",
    "    \"time<=\": \"2016-09-04T00:00:00Z\",\n",
    "    \"latitude>=\": 38.0,\n",
    "    \"latitude<=\": 41.0,\n",
    "}\n",
    "erddap.get_download_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = erddap.to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erddap_path = utils.CURRENT_NETCDF_DIR / \"roms_ncst_ae30_8a12_e3ca.nc\"\n",
    "dataset = xr.open_dataset(erddap_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"u\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_parcels",
   "language": "python",
   "name": "py3_parcels"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
