{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# particle_interp_compare\n",
    "\n",
    "compare particle simulations in different fieldsets with a single particle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from parcels import FieldSet, ParticleSet, JITParticle, AdvectionRK4, ErrorCode, plotTrajectoriesFile, ParticleFile\n",
    "\n",
    "from utils import create_path, add_noise\n",
    "from parcels_utils import get_file_info\n",
    "from plot_utils import plot_trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir1km = \"current_netcdfs/west_coast_1km_hourly/\"\n",
    "\n",
    "files = [\n",
    "    get_file_info(dir1km + \"tijuana_river_lin.nc\", 1, name=\"lin\"),\n",
    "    get_file_info(dir1km + \"tijuana_river_lin_aggr.nc\", 1, name=\"lin_aggr\")\n",
    "]\n",
    "\n",
    "st = files[0][\"timerng\"][0]\n",
    "ed = files[0][\"timerng\"][1]\n",
    "for f in files:\n",
    "    assert f[\"timerng\"][0] == st\n",
    "    assert f[\"timerng\"][1] == ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_sim = True\n",
    "end_time = files[0][\"timerng\"][1]\n",
    "# this was the very specific spawn time for particles that collided with land\n",
    "spawn_time = np.datetime64(\"2020-06-17T09:00:00\")\n",
    "max_var = 0.003\n",
    "spawn_loc_base = np.array([32.551707, -117.138]) # (lat, lon)\n",
    "spawn_locs = add_noise(spawn_loc_base, max_var, repeat=20)\n",
    "simulation_dt = timedelta(minutes=5)\n",
    "out_dt = timedelta(hours=1)\n",
    "save_dir = create_path(\"particledata/testcompare\")\n",
    "\n",
    "def DeleteParticle(particle, fieldset, time):\n",
    "    particle.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now i could just stuff everything into a single ParticleSet for every different spawn location\n",
    "\n",
    "but then it becomes annoying to filter out ones that start at a specific location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    f[\"psets\"] = np.empty(len(spawn_locs), dtype=ParticleSet)\n",
    "    f[\"pfiles\"] = np.empty(len(spawn_locs), dtype=ParticleFile)\n",
    "    \n",
    "    for i in range(len(spawn_locs)):\n",
    "        f[\"psets\"][i] = ParticleSet(fieldset=f[\"fs\"], pclass=JITParticle, lon=[spawn_locs[i][1]], lat=[spawn_locs[i][0]], time=[spawn_time])\n",
    "        save_path = f\"{save_dir}/{f['name']}{i}.nc\"\n",
    "        f[\"pfiles\"][i] = f[\"psets\"][i].ParticleFile(save_path, outputdt=out_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_sim:\n",
    "    for f in files:\n",
    "        for i in range(len(spawn_locs)):\n",
    "            f[\"psets\"][i].execute(\n",
    "                        AdvectionRK4,\n",
    "                        endtime=end_time,\n",
    "                        dt=simulation_dt,\n",
    "                        recovery={ErrorCode.ErrorOutOfBounds: DeleteParticle},\n",
    "                        output_file=f[\"pfiles\"][i]\n",
    "                    )\n",
    "            f[\"pfiles\"][i].export()\n",
    "            f[\"pfiles\"][i].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(files[0][\"domain\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mod_domain = {\n",
    "    'S': 32.545,\n",
    "    'N': 32.585,\n",
    "    'W': -117.158,\n",
    "    'E': -117.13\n",
    "}\n",
    "# mod_domain = {\n",
    "#     'S': 32.5495,\n",
    "#     'N': 32.555,\n",
    "#     'W': -117.15,\n",
    "#     'E': -117.135\n",
    "# }\n",
    "# mod_domain = {\n",
    "#     'S': 32.575,\n",
    "#     'N': 32.5766,\n",
    "#     'W': -117.145,\n",
    "#     'E': -117.140\n",
    "# }\n",
    "\n",
    "for i in range(len(spawn_locs)):\n",
    "    ps = np.array([f[\"pfiles\"][i].name for f in files])\n",
    "    print(f\"starting at (lat, lon) {spawn_locs[i]}\")\n",
    "#     plot_trajectories(ps, mod_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    ps = np.array([p.name for p in f[\"pfiles\"]])\n",
    "    print(f\"paths for {f['name']}\")\n",
    "    plot_trajectories(ps, mod_domain, legend=False, scatter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wack ass coordinates\n",
    "\n",
    "[  32.55096753 -117.13918667]\n",
    "\n",
    "[  32.55072813 -117.13842626]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_parcels",
   "language": "python",
   "name": "py3_parcels"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
