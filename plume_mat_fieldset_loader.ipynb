{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load mats into netcdfs from plume tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import xarray as xr\n",
    "\n",
    "from utils import create_gif, load_pts_mat\n",
    "from parcels_utils import xr_dataset_to_fieldset\n",
    "from plot_utils import get_carree_axis, plot_particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIJUANA_RIVER_DOMAIN = dict(\n",
    "    S=32.528,\n",
    "    N=32.71,\n",
    "    W=-117.29,\n",
    "    E=-117.11,\n",
    ")\n",
    "CLOSE_TIJUANA_DOMAIN = dict(\n",
    "    S=32.53,\n",
    "    N=32.5825,\n",
    "    W=-117.162,\n",
    "    E=-117.105,\n",
    ")\n",
    "THING_DOMAIN = {\n",
    "    \"S\": 32.41,\n",
    "    \"N\": 32.7,\n",
    "    \"W\": -117.25,\n",
    "    \"E\": -117\n",
    "}\n",
    "\n",
    "coastline = load_pts_mat(\"mat/coastline.mat\", \"latz0\", \"lonz0\")\n",
    "# just filter out the problematic upper coastline where it goes up and down\n",
    "coastline = coastline[:, :288]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(coastline[1], coastline[0], s=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord_inland(coastline, lat, lon):\n",
    "    lower_ind = np.where(coastline[0] <= lat)[0]\n",
    "    if lower_ind.size > 0:\n",
    "        lower_ind = lower_ind[-1]\n",
    "    else:\n",
    "        lower_ind = 0\n",
    "    upper_ind = np.where(coastline[0] >= lat)[0]\n",
    "    if upper_ind.size > 0:\n",
    "        upper_ind = upper_ind[0]\n",
    "    else:\n",
    "        upper_ind = -1\n",
    "    left = min(coastline[1][lower_ind], coastline[1][upper_ind])\n",
    "    # can get away with this since the coastline points are dense enough\n",
    "    return lon > left\n",
    "\n",
    "\n",
    "def parse_mat_time(time):\n",
    "    date = np.datetime64(\"0\") + np.timedelta64(int(time) - 1, \"D\")\n",
    "    hour = int(round((time - int(time)) * 24))\n",
    "    return date + np.timedelta64(hour, \"h\")\n",
    "\n",
    "\n",
    "def dataset_from_mat(grid_mat_path, current_mat_path, remove_land_currents):\n",
    "    grid_mat = scipy.io.loadmat(grid_mat_path)\n",
    "    current_mat = scipy.io.loadmat(current_mat_path)\n",
    "    coords = grid_mat[\"totalGrid\"]\n",
    "    u = current_mat[\"U\"]\n",
    "    v = current_mat[\"V\"]\n",
    "    time = np.array([parse_mat_time(current_mat[\"t\"][0, 0])])\n",
    "    lats = np.sort(np.unique(coords.T[1]))\n",
    "    lons = np.sort(np.unique(coords.T[0]))\n",
    "    u_grid = np.zeros((1, len(lats), len(lons)))\n",
    "    v_grid = np.zeros((1, len(lats), len(lons)))\n",
    "    for i in range(len(lons)):\n",
    "        for j in range(len(lats)):\n",
    "            if remove_land_currents and not np.isnan(u[0][i * len(lats) + j]) and coord_inland(coastline, lats[j], lons[i]):\n",
    "                u_grid[0, j, i] = np.nan\n",
    "                v_grid[0, j, i] = np.nan\n",
    "            else:\n",
    "                # data from .mat is measured in cm/s\n",
    "                u_grid[0, j, i] = u[0][i * len(lats) + j] / 100\n",
    "                v_grid[0, j, i] = v[0][i * len(lats) + j] / 100\n",
    "    ds = xr.Dataset(\n",
    "        {\n",
    "            \"u\": ([\"time\", \"lat\", \"lon\"], u_grid),\n",
    "            \"v\": ([\"time\", \"lat\", \"lon\"], v_grid),\n",
    "        },\n",
    "        coords={\n",
    "            \"time\": time,\n",
    "            \"lat\": lats,\n",
    "            \"lon\": lons\n",
    "        }\n",
    "    )\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_prefix = \"Tot_SDLJ_20200810\"\n",
    "start = 0\n",
    "incr = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ds_total = None\n",
    "for i in range(start, 2400, incr):\n",
    "    name = f\"mat/{file_prefix}_{str(i).zfill(4)}.mat\"\n",
    "    try:\n",
    "        ds = dataset_from_mat(\"mat/codartotalGrid.mat\", name, True)\n",
    "        if ds_total is None:\n",
    "            ds_total = ds\n",
    "        else:\n",
    "            ds_total = xr.concat([ds_total, ds], dim=\"time\")\n",
    "        data = scipy.io.loadmat(name)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"file {name} not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_total.to_netcdf(f\"current_netcdfs/{file_prefix}.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = xr_dataset_to_fieldset(ds_total)\n",
    "fs.U.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_parcels",
   "language": "python",
   "name": "py3_parcels"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
