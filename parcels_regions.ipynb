{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parcels regions\n",
    "\n",
    "runs parcels on existing netcdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import math\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from parcels import FieldSet, ParticleSet\n",
    "import scipy.io\n",
    "import xarray as xr\n",
    "\n",
    "import utils\n",
    "from parcels_utils import get_file_info\n",
    "from plot_utils import plot_particles_age\n",
    "\n",
    "# ignore annoying deprecation warnings\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "import cartopy\n",
    "\n",
    "# ignore divide by nan error that happens constantly with parcels\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## configuration\n",
    "\n",
    "change the contents of `configs` for the simulation configuration you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    # \"plume_track.json\",\n",
    "    # \"plume_track_totsdlj.json\",\n",
    "#     \"tijuana_interped.json\",\n",
    "#     \"tijuana_lin.json\",\n",
    "#     \"tijuana_lin_aggr.json\",\n",
    "#     \"tijuana_less.json\",\n",
    "#     \"tijuana_now.json\",\n",
    "#     \"tijuana_onerep.json\",\n",
    "#     \"tijuana_range.json\",\n",
    "    \"buoy_track.json\"\n",
    "]\n",
    "\n",
    "loaded_configs = [utils.load_config(utils.PARCELS_CONFIGS_DIR / path) for path in configs]\n",
    "files = [get_file_info(cfg[\"netcdf_path\"], cfg[\"resolution\"], name=cfg[\"name\"], parcels_cfg=cfg[\"parcels_config\"]) for cfg in loaded_configs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animated gif stuff and particle simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# animation man very cool\n",
    "# reference tutorial_Agulhasparticles\n",
    "# needs ErrorCode for particle recovery\n",
    "from operator import attrgetter\n",
    "from parcels import ErrorCode, JITParticle, Variable, AdvectionRK4\n",
    "\n",
    "max_v = 0.6 # for display purposes only, so the vector field colors don't change every iteration\n",
    "\n",
    "class ThreddsParticle(JITParticle):\n",
    "    lifetime = Variable(\"lifetime\", initial=0, dtype=np.float32)\n",
    "    spawntime = Variable(\"spawntime\", initial=attrgetter(\"time\"), dtype=np.float32)\n",
    "    # out of bounds\n",
    "    oob = Variable(\"oob\", initial=0, dtype=np.int32)\n",
    "    \n",
    "    \n",
    "def AgeParticle(particle, fieldset, time):\n",
    "    particle.lifetime += particle.dt\n",
    "    \n",
    "    \n",
    "def TestOOB(particle, fieldset, time):\n",
    "    u, v = fieldset.UV[time, particle.depth, particle.lat, particle.lon]\n",
    "    if math.fabs(u) < 1e-14 and math.fabs(v) < 1e-14:\n",
    "        particle.oob = 1\n",
    "    else:\n",
    "        particle.oob = 0\n",
    "\n",
    "\n",
    "def DeleteParticle(particle, fieldset, time):\n",
    "    print(\"Particle [%d] lost (%g %g %g %g)\" % (particle.id, particle.time, particle.depth, particle.lat, particle.lon), file=sys.stderr)\n",
    "    particle.delete()\n",
    "\n",
    "\n",
    "def exec_pset(data, runtime, dt):\n",
    "    if len(data[\"pset\"]) == 0:\n",
    "        print(\"ParticleSet is empty. Passing...\", file=sys.stderr)\n",
    "        return\n",
    "    \n",
    "    # temporary - TODO make it only init once\n",
    "    k_age = data[\"pset\"].Kernel(AgeParticle)\n",
    "    k_oob = data[\"pset\"].Kernel(TestOOB)\n",
    "\n",
    "    data[\"pset\"].execute(\n",
    "        AdvectionRK4 + k_age + k_oob,\n",
    "        runtime=timedelta(seconds=runtime),\n",
    "        dt=timedelta(seconds=dt),\n",
    "        recovery={ErrorCode.ErrorOutOfBounds: DeleteParticle},\n",
    "        output_file=data[\"pfile\"]\n",
    "    )\n",
    "\n",
    "\n",
    "def save_pset_plot(data, i, zpad=3, ages=True):\n",
    "    days = (data[\"timerng\"][1] - data[\"timerng\"][0]) / np.timedelta64(1, 'D')\n",
    "    field = None if ages else \"vector\"\n",
    "    if data[\"cfg\"][\"shown_domain\"] is not None:\n",
    "        dom = data[\"cfg\"][\"shown_domain\"]\n",
    "    else:\n",
    "        dom = data[\"domain\"]\n",
    "    plot_particles_age(data[\"pset\"], dom, field=field,\n",
    "                       savefile=str(data[\"snap_path\"])+\"/particles\"+str(i).zfill(zpad)+\".png\",\n",
    "                       vmax=days, field_vmax=max_v, part_size=4)\n",
    "        \n",
    "        \n",
    "def parse_time_range(time_range, data):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        time_range (array-like): some array with 2 strings\n",
    "        data (dict)\n",
    "    \"\"\"\n",
    "    if time_range[0] == \"START\":\n",
    "        t_start = data[\"timerng\"][0]\n",
    "    else:\n",
    "        try:\n",
    "            t_start = int(time_range[0])\n",
    "        except ValueError:\n",
    "            t_start = np.datetime64(time_range[0])\n",
    "\n",
    "    if time_range[1] == \"END\":\n",
    "        t_end = data[\"timerng\"][1]\n",
    "    else:\n",
    "        try:\n",
    "            t_end = int(time_range[1])\n",
    "        except ValueError:\n",
    "            t_end = np.datetime64(time_range[1])\n",
    "            \n",
    "    if isinstance(t_start, int) and isinstance(t_end, int):\n",
    "        raise TypeError(\"Must have at least one date in the time range.\")\n",
    "    if isinstance(t_start, int):\n",
    "        t_start = t_end - np.timedelta64(t_start)\n",
    "    if isinstance(t_end, int):\n",
    "        t_end = t_start + np.timedelta64(t_end)\n",
    "        \n",
    "    return t_start, t_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ParticleSet and spawn point setup\n",
    "\n",
    "note about interpolation methods: only `linear` works if you want to use the FieldSet in a ParticleSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "part_path = utils.create_path(utils.PARTICLE_NETCDF_DIR)\n",
    "\n",
    "for f in files:\n",
    "    cfg = f[\"cfg\"]\n",
    "    # data is from .mat file\n",
    "    if isinstance(cfg[\"spawn_points\"], str):\n",
    "        spawns = utils.load_pts_mat(cfg[\"spawn_points\"], \"yf\", \"xf\")\n",
    "        cfg[\"spawn_points\"] = spawns.T\n",
    "    else:\n",
    "        cfg[\"spawn_points\"] = np.array(cfg[\"spawn_points\"])\n",
    "    \n",
    "    # parse time information\n",
    "    t_start, t_end = parse_time_range(cfg[\"time_range\"], f)\n",
    "    # convert to seconds relative to fieldset delta\n",
    "    t_start = (t_start - f[\"timerng\"][0]) / np.timedelta64(1, \"s\")\n",
    "    t_end = (t_end - f[\"timerng\"][0]) / np.timedelta64(1, \"s\")\n",
    "            \n",
    "    if cfg[\"repeat_dt\"] <= 0:\n",
    "        repetitions = 1\n",
    "    else:\n",
    "        repetitions = int((t_end - t_start) / cfg[\"repeat_dt\"])\n",
    "    cfg[\"sim_start_sec\"] = t_start\n",
    "    cfg[\"sim_end_sec\"] = t_end\n",
    "    # the total number of particles that will exist in the simulation\n",
    "    if cfg[\"particles_per_dt\"] <= 0:\n",
    "        cfg[\"particles_per_dt\"] = len(cfg[\"spawn_points\"])\n",
    "        total = repetitions * len(cfg[\"spawn_points\"])\n",
    "    else:\n",
    "        total = repetitions * cfg[\"particles_per_dt\"]\n",
    "\n",
    "    # prep when each particle is released\n",
    "    time_arr = np.zeros(total)\n",
    "    for i in range(repetitions):\n",
    "        # should be fine if repeat_dt is negative since it will be multiplied by 0\n",
    "        # when that's the case\n",
    "        time_arr[cfg[\"particles_per_dt\"] * i:cfg[\"particles_per_dt\"] * (i + 1)] = t_start + cfg[\"repeat_dt\"] * i\n",
    "\n",
    "    # select spawn points from the given config\n",
    "    if cfg[\"random_spawn\"]:\n",
    "        # randomly choose spawn points and random vairation\n",
    "        sp_lat = cfg[\"spawn_points\"].T[0][np.random.randint(0, len(cfg[\"spawn_points\"]), total)]\n",
    "        sp_lon = cfg[\"spawn_points\"].T[1][np.random.randint(0, len(cfg[\"spawn_points\"]), total)]\n",
    "        # vary spawn locations using max_variation\n",
    "        p_lats = utils.add_noise(sp_lat, cfg[\"max_variation\"])\n",
    "        p_lons = utils.add_noise(sp_lon, cfg[\"max_variation\"])\n",
    "    else:\n",
    "        # cycle through each spawn point in order\n",
    "        sp_repeat = int(total / len(cfg[\"spawn_points\"]))\n",
    "        remainder = total - sp_repeat * len(cfg[\"spawn_points\"])\n",
    "        p_lats = np.empty(total)\n",
    "        p_lons = np.empty(total)\n",
    "        p_lats[:sp_repeat * len(cfg[\"spawn_points\"])] = np.tile(cfg[\"spawn_points\"].T[0], sp_repeat)\n",
    "        p_lats[sp_repeat * len(cfg[\"spawn_points\"]):] = cfg[\"spawn_points\"].T[0][:remainder]\n",
    "        p_lons[:sp_repeat * len(cfg[\"spawn_points\"])] = np.tile(cfg[\"spawn_points\"].T[1], sp_repeat)\n",
    "        p_lons[sp_repeat * len(cfg[\"spawn_points\"]):] = cfg[\"spawn_points\"].T[1][:remainder]\n",
    "\n",
    "    # set up ParticleSet and ParticleFile\n",
    "    f[\"pset\"] = ParticleSet(fieldset=f[\"fs\"], pclass=ThreddsParticle, lon=p_lons, lat=p_lats, time=time_arr)\n",
    "    save_path = part_path / f\"particle_{f['name']}.nc\"\n",
    "    f[\"pfile\"] = f[\"pset\"].ParticleFile(save_path)\n",
    "    print(f\"Particle trajectories for {f['name']} will be saved to {save_path}\")\n",
    "    print(f\"    total particles in simulation: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[f[\"pset\"].show(field=\"vector\", vmax=max_v) for f in files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simulation setup and execution\n",
    "\n",
    "simulation parameter setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# setting up times, intervals, and paths for simulation\n",
    "for f in files:\n",
    "    cfg = f[\"cfg\"]\n",
    "    cfg[\"snap_num\"] = math.floor((cfg[\"sim_end_sec\"] - cfg[\"sim_start_sec\"]) / cfg[\"snapshot_interval\"])\n",
    "    cfg[\"last_int\"] = cfg[\"sim_end_sec\"] - (cfg[\"snap_num\"] * cfg[\"snapshot_interval\"] + cfg[\"sim_start_sec\"])\n",
    "    if cfg[\"last_int\"] == 0:\n",
    "        print(\"No last interval exists.\")\n",
    "        print(f\"Num snapshots to save for {f['path']}: {cfg['snap_num'] + 1}\")\n",
    "    else:\n",
    "        print(f\"Num snapshots to save for {f['path']}: {cfg['snap_num'] + 2}\")\n",
    "    if cfg[\"snap_num\"] >= 200 and cfg[\"save_snapshots\"]:\n",
    "        raise Exception(f\"Too many snapshots ({cfg['snap_num']}).\")\n",
    "    f[\"snap_path\"] = utils.create_path(utils.PICUTRE_DIR / f\"{utils.filename_dict[f['res']]}/{f['name']}\")\n",
    "    print(f\"Path to save snapshots to: {f['snap_path']}\")\n",
    "    # only clear directory if desired or actually saving images\n",
    "    if cfg[\"save_snapshots\"]:\n",
    "        for p in f[\"snap_path\"].glob(\"*.png\"):\n",
    "            p.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "execution of all simulation configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# show age or not (temporary)\n",
    "age = False\n",
    "# execution of simulation\n",
    "for f in files:\n",
    "    cfg = f[\"cfg\"]\n",
    "    if cfg[\"save_snapshots\"]:\n",
    "        save_pset_plot(f, 0, ages=age)\n",
    "    for i in range(cfg[\"snap_num\"]):\n",
    "        exec_pset(f, cfg[\"snapshot_interval\"], cfg[\"simulation_dt\"])\n",
    "        if cfg[\"save_snapshots\"]:\n",
    "            save_pset_plot(f, i + 1, ages=age)\n",
    "\n",
    "    # save the second-to-last frame\n",
    "    if cfg[\"save_snapshots\"]:\n",
    "        save_pset_plot(f, cfg[\"snap_num\"] + 1, ages=age)\n",
    "\n",
    "    # run the last interval (the remainder) if needed\n",
    "    if cfg[\"last_int\"] != 0:\n",
    "        exec_pset(f, cfg[\"snapshot_interval\"], cfg[\"simulation_dt\"])\n",
    "        if cfg[\"save_snapshots\"]:\n",
    "            save_pset_plot(f, cfg[\"snap_num\"] + 2, ages=age)\n",
    "        \n",
    "    # run one more time with 0 runtime because for some reason\n",
    "    # particles can be out-of-bounds without being deleted\n",
    "    # ??? how does this happen ???\n",
    "    # im not actually sure if this really does anything but hey its worth a shot\n",
    "    exec_pset(f, 0, 0)\n",
    "        \n",
    "    f[\"pfile\"].export()\n",
    "    f[\"pfile\"].close()\n",
    "\n",
    "print(\"all simulations done and snapshots saved (if simulation was saving snapshots)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gif generation\n",
    "\n",
    "don't have to run, requires [magick](https://imagemagick.org/index.php)\n",
    "\n",
    "the gifs will be saved `snapshots/west_coast_xkm_hourly/` where xkm is the resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "gif_delay = 25 # ms\n",
    "\n",
    "for f in files:\n",
    "    if f[\"cfg\"][\"save_snapshots\"]:\n",
    "        utils.create_gif(\n",
    "            gif_delay,\n",
    "            str(f[\"snap_path\"]) + \"/*.png\",\n",
    "            utils.PICUTRE_DIR / f\"{utils.filename_dict[f['res']]}/partsim_{f['name']}.gif\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"no gif generated\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_parcels",
   "language": "python",
   "name": "py3_parcels"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
